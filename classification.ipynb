{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Dataset: [20newgroups](http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset) of sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dict_keys(['description', 'target', 'target_names', 'data', 'filenames', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "#To speed up processing, we retrieve a subset of the 20 topics in the dataset\n",
    "categories =  ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "# get data for training\n",
    "train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# get data for testing\n",
    "test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\n\",train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Let us first convert the collection of text documents to a matrix of token counts with CountVectorizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "# teach and transform train data\n",
    "train_token = count_vec.fit_transform(train.data)\n",
    "\n",
    "# just transform test data\n",
    "test_token = count_vec.transform(test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to feed predictive or clustering models with the text data, we need to turn the text into vectors of numerical values suitable for statistical analysis. Reduce the weight of very common words by using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf = TfidfTransformer()\n",
    "# teach and transform train_token\n",
    "train_tf = tf.fit_transform(train_token)\n",
    "\n",
    "# transform test\n",
    "test_tf = tf.transform(test_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two steps can be done with TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "# teach and transform train_token\n",
    "train_tv = tv.fit_transform(train.data)\n",
    "\n",
    "# transform test\n",
    "test_tv = tv.transform(test.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76564580559254325"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier().fit(train_tv, train.target)\n",
    "knn_prediction = knn.predict(test_tv)\n",
    "\n",
    "knn.score(test_tv, test.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76564580559254325"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier().fit(train_tf, train.target)\n",
    "knn_prediction = knn.predict(test_tf)\n",
    "\n",
    "knn.score(test_tf, test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is not that good. Let's see if we get better result with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796271637816\n",
      "{'n_neighbors': 1}\n",
      "Best score:  0.899867080195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_neighbors':[1,2,3,4,5,7,10]}\n",
    "\n",
    "knn_cv = GridSearchCV(knn, parameters).fit(train_tf, train.target)\n",
    "knn_cv_prediction = knn_cv.predict(test_tf)\n",
    "\n",
    "sorted(knn_cv.cv_results_.keys())\n",
    "print(knn_cv.best_params_)\n",
    "print(\"Best score: \", knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "keys to remember: \n",
    "* Kernels\n",
    "* Kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92077230359520634"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel = 'linear', C=1.0).fit(train_tv, train.target)\n",
    "svc_prediction = svc.predict(test_tv)\n",
    "\n",
    "svc.score(test_tv, test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is better but let see if we can do better with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922103861518\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "Best score:  0.965883916704\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 15]}\n",
    "svc_cv = GridSearchCV(svc, parameters).fit(train_tv, train.target)\n",
    "svc_cv_prediction = svc_cv.predict(test_tv)\n",
    "\n",
    "sorted(svc_cv.cv_results_.keys())\n",
    "print(svc_cv.best_params_)\n",
    "print(\"Best score: \", svc_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "keys to remember: \n",
    "* Entropy\n",
    "* Tend to overfitt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717043941411\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier().fit(train_tv, train.target)\n",
    "dt_prediction = dt.predict(train_tv)\n",
    "print(dt.score(test_tv, test.target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Avoid overfitting using k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782014111989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt, train_tv, train.target, cv=5)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid overfitting using Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735019973369\n",
      "{'n_estimators': 90}\n",
      "Best score:  0.880372175454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier().fit(train_tv, train.target)\n",
    "rf_prediction = rf.predict(test_tv)\n",
    "print(rf.score(test_tv, test.target))\n",
    "\n",
    "parameters = {'n_estimators':[1, 10, 15, 20, 30, 90]}\n",
    "rf_cv = GridSearchCV(rf, parameters).fit(train_tv, train.target)\n",
    "rf_cv_prediction = rf_cv.predict(test_tv)\n",
    "\n",
    "\n",
    "print(rf_cv.best_params_)\n",
    "print(\"Best score: \", rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834886817577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(train_tv, train.target)\n",
    "nb_prediction = nb.predict(test_tv)\n",
    "\n",
    "print(nb.score(test_tv, test.target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
